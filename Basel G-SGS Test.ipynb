{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle\n",
      "\n",
      "with open('/vol/data/frgc_spring2003_sfs_spherical_tps', 'rb') as f:\n",
      "    model = cPickle.load(f)\n",
      "\n",
      "normal_model = model['appearance_model']\n",
      "reference_frame = model['template']\n",
      "mean_normals = model['mean_normals']\n",
      "reference_frame = model['template']\n",
      "try:\n",
      "    intrinsic_mean_normals = model['intrinsic_mean_normals']\n",
      "except Exception:\n",
      "    pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.io import auto_import\n",
      "\n",
      "intensity_image = auto_import('/home/pts08/research/sfs/celebrities/4.png')[0].as_greyscale()\n",
      "intensity_image.crop_to_landmarks()\n",
      "intensity_image.constrain_mask_to_landmarks()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.linalg import pinv2\n",
      "n = mean_normals.as_vector(keep_channels=True)\n",
      "I = intensity_image.as_vector()\n",
      "estimate_light = np.dot(pinv2(n), I)\n",
      "print estimate_light"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.image import MaskedNDImage\n",
      "from geometric_sfs import geometric_sfs as sfs\n",
      "from mapping import ImageMapper, PGA, AEP, Spherical, IdentityMapper\n",
      "from vector_utils import normalise_vector\n",
      "mapping_object = ImageMapper(Spherical())\n",
      "\n",
      "warped_intensity_image = MaskedNDImage(intensity_image.pixels, mask=intensity_image.mask)\n",
      "# Normalise the image so that it has unit albedo?\n",
      "# warped_intensity_image.masked_pixels /= ground_truth_albedo.masked_pixels\n",
      "# warped_intensity_image.masked_pixels /= np.max(warped_intensity_image.masked_pixels)\n",
      "reconstructed_normals = sfs(warped_intensity_image, mean_normals, normal_model, estimate_light, n_iters=200, mapping_object=mapping_object)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from geometric_sfs import horn_brooks\n",
      "reconstructed_normals_horn = horn_brooks(warped_intensity_image, mean_normals, normal_model, estimate_light, n_iters=200, c_lambda=50, mapping_object=mapping_object)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.visualize.viewmayavi import MayaviVectorViewer3d\n",
      "import mayavi.mlab as mlab\n",
      "\n",
      "reconstructed_normals.view_new(channel=0)\n",
      "reconstructed_normals_horn.view_new(channel=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from surface_reconstruction import frankotchellappa, gradient_field_from_normals\n",
      "gradient_field = gradient_field_from_normals(reconstructed_normals)\n",
      "recovered_depth = frankotchellappa(gradient_field.pixels[:, :, 0], gradient_field.pixels[:, :, 1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gradient_field = gradient_field_from_normals(reconstructed_normals_horn)\n",
      "recovered_depth_horn = frankotchellappa(gradient_field.pixels[:, :, 0], gradient_field.pixels[:, :, 1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.image import DepthImage, RGBImage\n",
      "temp_texture = np.concatenate([warped_intensity_image.pixels]*3, axis=2)\n",
      "\n",
      "recovered_depth_image = DepthImage((recovered_depth - np.min(recovered_depth)) / 2, texture=RGBImage(temp_texture))\n",
      "recovered_depth_horn_image = DepthImage((recovered_depth_horn - np.min(recovered_depth_horn)) / 2, texture=RGBImage(temp_texture))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "recovered_depth_image.view_new(mode='mesh')\n",
      "recovered_depth_horn_image.view_new(mode='mesh')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.ndimage.filters\n",
      "from pybug.image import ShapeImage\n",
      "DepthImage(scipy.ndimage.filters.gaussian_filter(recovered_depth_horn_image.pixels[:, :, 0], 5.0), texture=RGBImage(temp_texture)).view_new(mode='mesh')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}