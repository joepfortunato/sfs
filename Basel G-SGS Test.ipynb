{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle\n",
      "\n",
      "with open('/vol/data/basel_sfs_normal_sim', 'rb') as f:\n",
      "    model = cPickle.load(f)\n",
      "\n",
      "normal_model = model['appearance_model']\n",
      "reference_frame = model['template']\n",
      "\n",
      "with open('/vol/atlas/pts08/basel_python_4.pkl', 'rb') as f:\n",
      "    test_set = cPickle.load(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.io import auto_import\n",
      "\n",
      "intensity_image = auto_import('/vol/atlas/databases/alex_images/bln1.ppm')[0].as_greyscale()\n",
      "intensity_image.landmarks['IBUG'] = intensity_image.landmarks['PTS']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.image import MaskedNDImage\n",
      "\n",
      "bln = auto_import('/vol/atlas/databases/alex_images/bln*.ppm')\n",
      "# Create a 4 channel image where each channel is the greyscale of an image\n",
      "ground_truth_images = MaskedNDImage(np.concatenate([im.as_greyscale().pixels for im in bln], axis=2))\n",
      "\n",
      "lights = np.array([[ 0.5,  0.4, 2],\n",
      "                   [-0.5,  0.4, 2],\n",
      "                   [-0.5, -0.4, 2],\n",
      "                   [ 0.5, -0.4, 2]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.transform import SimilarityTransform\n",
      "from pybug.shape import PointCloud\n",
      "\n",
      "L_E_X = intensity_image.landmarks['IBUG'].lms.points[1, 1]\n",
      "L_E_Y = intensity_image.landmarks['IBUG'].lms.points[1, 0]\n",
      "\n",
      "R_E_X = intensity_image.landmarks['IBUG'].lms.points[2, 1]\n",
      "R_E_Y = intensity_image.landmarks['IBUG'].lms.points[2, 0]\n",
      "\n",
      "Nose_X = intensity_image.landmarks['IBUG'].lms.points[0, 1]\n",
      "Nose_Y = intensity_image.landmarks['IBUG'].lms.points[0, 0]\n",
      "\n",
      "Low_X = intensity_image.landmarks['IBUG'].lms.points[3, 1]\n",
      "Low_Y= intensity_image.landmarks['IBUG'].lms.points[3, 0]\n",
      "\n",
      "original_landmarks = np.array([[L_E_Y, L_E_X], \n",
      "                               [Nose_Y, Nose_X], \n",
      "                               [Low_Y, Low_X], \n",
      "                               [R_E_Y, R_E_X]])\n",
      "\n",
      "# Build the template face (xs)\n",
      "L_E_X = 24;\n",
      "R_E_X = 336;\n",
      "Nose_X = 180;\n",
      "Low_X = 180;\n",
      "\n",
      "# Build the template face (ys)\n",
      "L_E_Y = 112;\n",
      "R_E_Y = 112;\n",
      "Nose_Y = 282;\n",
      "Low_Y = 452;\n",
      "\n",
      "face_template = np.array([[L_E_Y, L_E_X], \n",
      "                          [Nose_Y, Nose_X], \n",
      "                          [Low_Y, Low_X], \n",
      "                          [R_E_Y, R_E_X]])\n",
      "tr = SimilarityTransform.align(PointCloud(face_template), PointCloud(original_landmarks))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.transform import SimilarityTransform\n",
      "from pybug.image import MaskedNDImage, IntensityImage\n",
      "\n",
      "warped_intensity_image = intensity_image.warp_to(reference_frame.mask, tr)\n",
      "warped_ground_truth_image = ground_truth_images.warp_to(reference_frame.mask, tr)\n",
      "\n",
      "warped_intensity_image = MaskedNDImage(warped_intensity_image.pixels, mask=warped_intensity_image.mask)\n",
      "warped_intensity_image.view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.linalg import pinv2\n",
      "n = normal_model.mean.as_vector(keep_channels=True)\n",
      "I = warped_intensity_image.as_vector()\n",
      "estimate_light = np.dot(pinv2(n), I)\n",
      "# Use ground truth light\n",
      "estimate_light = lights[0, :]\n",
      "print estimate_light"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from photometric_stereo import photometric_stereo as ps\n",
      "\n",
      "ground_truth_normals, ground_truth_albedo = ps(warped_ground_truth_image, lights)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.image import MaskedNDImage\n",
      "from geometric_sfs import geometric_sfs as sfs\n",
      "from pga import PGA\n",
      "from vector_utils import normalise_vector\n",
      "\n",
      "warped_intensity_image = MaskedNDImage(warped_intensity_image.pixels, mask=warped_intensity_image.mask)\n",
      "# Normalise the image so that it has unit albedo?\n",
      "# warped_intensity_image.masked_pixels /= ground_truth_albedo.masked_pixels\n",
      "# warped_intensity_image.masked_pixels /= np.max(warped_intensity_image.masked_pixels)\n",
      "reconstructed_normals = sfs(warped_intensity_image, normal_model, estimate_light, max_iters=200)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from geometric_sfs import horn_brooks\n",
      "reconstructed_normals_horn = horn_brooks(warped_intensity_image, normal_model, estimate_light, max_iters=100, c_lambda=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.visualize.viewmayavi import MayaviVectorViewer3d\n",
      "import mayavi.mlab as mlab\n",
      "\n",
      "reconstructed_normals.view_new(channel=0)\n",
      "ground_truth_normals.view_new(channel=0)\n",
      "reconstructed_normals_horn.view_new(channel=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gradient_field_from_normals(normals):\n",
      "    vector = normals.as_vector(keep_channels=True)\n",
      "    gradient_field = np.zeros([vector.shape[0], 2])\n",
      "    gradient_field[:, 0] = vector[:, 0] / vector[:, 2]\n",
      "    gradient_field[:, 1] = vector[:, 1] / vector[:, 2]\n",
      "    gradient_field[np.isinf(gradient_field)] = 0.0\n",
      "    gradient_field[np.isnan(gradient_field)] = 0.0\n",
      "    return normals.from_vector(gradient_field, n_channels=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from surface_reconstruction import frankotchellappa\n",
      "gradient_field = gradient_field_from_normals(reconstructed_normals)\n",
      "recovered_depth = frankotchellappa(gradient_field.pixels[:, :, 0], gradient_field.pixels[:, :, 1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gradient_field = gradient_field_from_normals(ground_truth_normals)\n",
      "ground_truth_depth = frankotchellappa(gradient_field.pixels[:, :, 0], gradient_field.pixels[:, :, 1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gradient_field = gradient_field_from_normals(reconstructed_normals_horn)\n",
      "recovered_depth_horn = frankotchellappa(gradient_field.pixels[:, :, 0], gradient_field.pixels[:, :, 1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.image import DepthImage, RGBImage\n",
      "temp_texture = np.concatenate([warped_intensity_image.pixels]*3, axis=2)\n",
      "\n",
      "recovered_depth_image = DepthImage((recovered_depth - np.min(recovered_depth)) / 2, texture=RGBImage(temp_texture))\n",
      "ground_truth_depth_image = DepthImage((ground_truth_depth - np.min(ground_truth_depth)) / 2, texture=RGBImage(temp_texture))\n",
      "recovered_depth_horn_image = DepthImage((recovered_depth_horn - np.min(recovered_depth_horn)) / 2, texture=RGBImage(temp_texture))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "recovered_depth_image.view_new(mode='mesh')\n",
      "ground_truth_depth_image.view_new(mode='mesh')\n",
      "recovered_depth_horn_image.view_new(mode='mesh')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.ndimage.filters\n",
      "from pybug.image import ShapeImage\n",
      "DepthImage(scipy.ndimage.filters.gaussian_filter(recovered_depth_horn_image.pixels[:, :, 0], 5.0), texture=RGBImage(temp_texture)).view_new(mode='mesh')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}